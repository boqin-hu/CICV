// Generated by gencpp from file perception_msgs/CameraObject.msg
// DO NOT EDIT!


#ifndef PERCEPTION_MSGS_MESSAGE_CAMERAOBJECT_H
#define PERCEPTION_MSGS_MESSAGE_CAMERAOBJECT_H


#include <string>
#include <vector>
#include <memory>

#include <ros/types.h>
#include <ros/serialization.h>
#include <ros/builtin_message_traits.h>
#include <ros/message_operations.h>

#include <std_msgs/Header.h>
#include <geometry_msgs/Point32.h>
#include <geometry_msgs/Vector3.h>
#include <geometry_msgs/Vector3.h>
#include <geometry_msgs/Vector3.h>
#include <perception_msgs/Point2D.h>
#include <perception_msgs/Point2D.h>

namespace perception_msgs
{
template <class ContainerAllocator>
struct CameraObject_
{
  typedef CameraObject_<ContainerAllocator> Type;

  CameraObject_()
    : header()
    , sensor_id(0)
    , object_id(0)
    , detect_confidence(0.0)
    , type_confidence(0.0)
    , azimuth(0.0)
    , yaw(0.0)
    , type(0)
    , tracking_time(0.0)
    , tracking_level(0)
    , lane_assignment(0)
    , position()
    , velocity()
    , acceleration()
    , dimensions()
    , pixel_central_point()
    , pixel_box_size()  {
    }
  CameraObject_(const ContainerAllocator& _alloc)
    : header(_alloc)
    , sensor_id(0)
    , object_id(0)
    , detect_confidence(0.0)
    , type_confidence(0.0)
    , azimuth(0.0)
    , yaw(0.0)
    , type(0)
    , tracking_time(0.0)
    , tracking_level(0)
    , lane_assignment(0)
    , position(_alloc)
    , velocity(_alloc)
    , acceleration(_alloc)
    , dimensions(_alloc)
    , pixel_central_point(_alloc)
    , pixel_box_size(_alloc)  {
  (void)_alloc;
    }



   typedef  ::std_msgs::Header_<ContainerAllocator>  _header_type;
  _header_type header;

   typedef uint8_t _sensor_id_type;
  _sensor_id_type sensor_id;

   typedef uint32_t _object_id_type;
  _object_id_type object_id;

   typedef float _detect_confidence_type;
  _detect_confidence_type detect_confidence;

   typedef float _type_confidence_type;
  _type_confidence_type type_confidence;

   typedef float _azimuth_type;
  _azimuth_type azimuth;

   typedef float _yaw_type;
  _yaw_type yaw;

   typedef uint8_t _type_type;
  _type_type type;

   typedef float _tracking_time_type;
  _tracking_time_type tracking_time;

   typedef int8_t _tracking_level_type;
  _tracking_level_type tracking_level;

   typedef int8_t _lane_assignment_type;
  _lane_assignment_type lane_assignment;

   typedef  ::geometry_msgs::Point32_<ContainerAllocator>  _position_type;
  _position_type position;

   typedef  ::geometry_msgs::Vector3_<ContainerAllocator>  _velocity_type;
  _velocity_type velocity;

   typedef  ::geometry_msgs::Vector3_<ContainerAllocator>  _acceleration_type;
  _acceleration_type acceleration;

   typedef  ::geometry_msgs::Vector3_<ContainerAllocator>  _dimensions_type;
  _dimensions_type dimensions;

   typedef  ::perception_msgs::Point2D_<ContainerAllocator>  _pixel_central_point_type;
  _pixel_central_point_type pixel_central_point;

   typedef  ::perception_msgs::Point2D_<ContainerAllocator>  _pixel_box_size_type;
  _pixel_box_size_type pixel_box_size;





  typedef boost::shared_ptr< ::perception_msgs::CameraObject_<ContainerAllocator> > Ptr;
  typedef boost::shared_ptr< ::perception_msgs::CameraObject_<ContainerAllocator> const> ConstPtr;

}; // struct CameraObject_

typedef ::perception_msgs::CameraObject_<std::allocator<void> > CameraObject;

typedef boost::shared_ptr< ::perception_msgs::CameraObject > CameraObjectPtr;
typedef boost::shared_ptr< ::perception_msgs::CameraObject const> CameraObjectConstPtr;

// constants requiring out of line definition



template<typename ContainerAllocator>
std::ostream& operator<<(std::ostream& s, const ::perception_msgs::CameraObject_<ContainerAllocator> & v)
{
ros::message_operations::Printer< ::perception_msgs::CameraObject_<ContainerAllocator> >::stream(s, "", v);
return s;
}


template<typename ContainerAllocator1, typename ContainerAllocator2>
bool operator==(const ::perception_msgs::CameraObject_<ContainerAllocator1> & lhs, const ::perception_msgs::CameraObject_<ContainerAllocator2> & rhs)
{
  return lhs.header == rhs.header &&
    lhs.sensor_id == rhs.sensor_id &&
    lhs.object_id == rhs.object_id &&
    lhs.detect_confidence == rhs.detect_confidence &&
    lhs.type_confidence == rhs.type_confidence &&
    lhs.azimuth == rhs.azimuth &&
    lhs.yaw == rhs.yaw &&
    lhs.type == rhs.type &&
    lhs.tracking_time == rhs.tracking_time &&
    lhs.tracking_level == rhs.tracking_level &&
    lhs.lane_assignment == rhs.lane_assignment &&
    lhs.position == rhs.position &&
    lhs.velocity == rhs.velocity &&
    lhs.acceleration == rhs.acceleration &&
    lhs.dimensions == rhs.dimensions &&
    lhs.pixel_central_point == rhs.pixel_central_point &&
    lhs.pixel_box_size == rhs.pixel_box_size;
}

template<typename ContainerAllocator1, typename ContainerAllocator2>
bool operator!=(const ::perception_msgs::CameraObject_<ContainerAllocator1> & lhs, const ::perception_msgs::CameraObject_<ContainerAllocator2> & rhs)
{
  return !(lhs == rhs);
}


} // namespace perception_msgs

namespace ros
{
namespace message_traits
{





template <class ContainerAllocator>
struct IsMessage< ::perception_msgs::CameraObject_<ContainerAllocator> >
  : TrueType
  { };

template <class ContainerAllocator>
struct IsMessage< ::perception_msgs::CameraObject_<ContainerAllocator> const>
  : TrueType
  { };

template <class ContainerAllocator>
struct IsFixedSize< ::perception_msgs::CameraObject_<ContainerAllocator> >
  : FalseType
  { };

template <class ContainerAllocator>
struct IsFixedSize< ::perception_msgs::CameraObject_<ContainerAllocator> const>
  : FalseType
  { };

template <class ContainerAllocator>
struct HasHeader< ::perception_msgs::CameraObject_<ContainerAllocator> >
  : TrueType
  { };

template <class ContainerAllocator>
struct HasHeader< ::perception_msgs::CameraObject_<ContainerAllocator> const>
  : TrueType
  { };


template<class ContainerAllocator>
struct MD5Sum< ::perception_msgs::CameraObject_<ContainerAllocator> >
{
  static const char* value()
  {
    return "411f3ce7123561d2bd0f9079d3ec3e83";
  }

  static const char* value(const ::perception_msgs::CameraObject_<ContainerAllocator>&) { return value(); }
  static const uint64_t static_value1 = 0x411f3ce7123561d2ULL;
  static const uint64_t static_value2 = 0xbd0f9079d3ec3e83ULL;
};

template<class ContainerAllocator>
struct DataType< ::perception_msgs::CameraObject_<ContainerAllocator> >
{
  static const char* value()
  {
    return "perception_msgs/CameraObject";
  }

  static const char* value(const ::perception_msgs::CameraObject_<ContainerAllocator>&) { return value(); }
};

template<class ContainerAllocator>
struct Definition< ::perception_msgs::CameraObject_<ContainerAllocator> >
{
  static const char* value()
  {
    return "Header header\n"
"\n"
"uint8  sensor_id  # sensor id, 0-front_long_focus, 1-front_short_focus, 2-right, 3-rear, 4-left\n"
"uint32 object_id\n"
"float32 detect_confidence\n"
"float32 type_confidence\n"
"float32 azimuth\n"
"float32 yaw  # car-body(R-F-U)  R--0, F--90,  (0,360)\n"
"\n"
"uint8 type  # 0--unknown 1--pedestrian 2--cyclist 3--car 4--truck\n"
"float32 tracking_time   #\n"
"int8 tracking_level     #\n"
"int8 lane_assignment    #\n"
"\n"
"geometry_msgs/Point32 position  # relative position, car-body(R-F-U)\n"
"geometry_msgs/Vector3 velocity  # relative velocity, car-body(R-F-U)\n"
"geometry_msgs/Vector3 acceleration  # relative acceleration, car-body(R-F-U)\n"
"geometry_msgs/Vector3 dimensions  # the scale of obj  x--length, y--width, z--height\n"
"\n"
"Point2D pixel_central_point \n"
"Point2D pixel_box_size\n"
"\n"
"\n"
" \n"
"\n"
"\n"
"\n"
"================================================================================\n"
"MSG: std_msgs/Header\n"
"# Standard metadata for higher-level stamped data types.\n"
"# This is generally used to communicate timestamped data \n"
"# in a particular coordinate frame.\n"
"# \n"
"# sequence ID: consecutively increasing ID \n"
"uint32 seq\n"
"#Two-integer timestamp that is expressed as:\n"
"# * stamp.sec: seconds (stamp_secs) since epoch (in Python the variable is called 'secs')\n"
"# * stamp.nsec: nanoseconds since stamp_secs (in Python the variable is called 'nsecs')\n"
"# time-handling sugar is provided by the client library\n"
"time stamp\n"
"#Frame this data is associated with\n"
"string frame_id\n"
"\n"
"================================================================================\n"
"MSG: geometry_msgs/Point32\n"
"# This contains the position of a point in free space(with 32 bits of precision).\n"
"# It is recommeded to use Point wherever possible instead of Point32.  \n"
"# \n"
"# This recommendation is to promote interoperability.  \n"
"#\n"
"# This message is designed to take up less space when sending\n"
"# lots of points at once, as in the case of a PointCloud.  \n"
"\n"
"float32 x\n"
"float32 y\n"
"float32 z\n"
"================================================================================\n"
"MSG: geometry_msgs/Vector3\n"
"# This represents a vector in free space. \n"
"# It is only meant to represent a direction. Therefore, it does not\n"
"# make sense to apply a translation to it (e.g., when applying a \n"
"# generic rigid transformation to a Vector3, tf2 will only apply the\n"
"# rotation). If you want your data to be translatable too, use the\n"
"# geometry_msgs/Point message instead.\n"
"\n"
"float64 x\n"
"float64 y\n"
"float64 z\n"
"================================================================================\n"
"MSG: perception_msgs/Point2D\n"
"float64 x\n"
"float64 y\n"
;
  }

  static const char* value(const ::perception_msgs::CameraObject_<ContainerAllocator>&) { return value(); }
};

} // namespace message_traits
} // namespace ros

namespace ros
{
namespace serialization
{

  template<class ContainerAllocator> struct Serializer< ::perception_msgs::CameraObject_<ContainerAllocator> >
  {
    template<typename Stream, typename T> inline static void allInOne(Stream& stream, T m)
    {
      stream.next(m.header);
      stream.next(m.sensor_id);
      stream.next(m.object_id);
      stream.next(m.detect_confidence);
      stream.next(m.type_confidence);
      stream.next(m.azimuth);
      stream.next(m.yaw);
      stream.next(m.type);
      stream.next(m.tracking_time);
      stream.next(m.tracking_level);
      stream.next(m.lane_assignment);
      stream.next(m.position);
      stream.next(m.velocity);
      stream.next(m.acceleration);
      stream.next(m.dimensions);
      stream.next(m.pixel_central_point);
      stream.next(m.pixel_box_size);
    }

    ROS_DECLARE_ALLINONE_SERIALIZER
  }; // struct CameraObject_

} // namespace serialization
} // namespace ros

namespace ros
{
namespace message_operations
{

template<class ContainerAllocator>
struct Printer< ::perception_msgs::CameraObject_<ContainerAllocator> >
{
  template<typename Stream> static void stream(Stream& s, const std::string& indent, const ::perception_msgs::CameraObject_<ContainerAllocator>& v)
  {
    s << indent << "header: ";
    s << std::endl;
    Printer< ::std_msgs::Header_<ContainerAllocator> >::stream(s, indent + "  ", v.header);
    s << indent << "sensor_id: ";
    Printer<uint8_t>::stream(s, indent + "  ", v.sensor_id);
    s << indent << "object_id: ";
    Printer<uint32_t>::stream(s, indent + "  ", v.object_id);
    s << indent << "detect_confidence: ";
    Printer<float>::stream(s, indent + "  ", v.detect_confidence);
    s << indent << "type_confidence: ";
    Printer<float>::stream(s, indent + "  ", v.type_confidence);
    s << indent << "azimuth: ";
    Printer<float>::stream(s, indent + "  ", v.azimuth);
    s << indent << "yaw: ";
    Printer<float>::stream(s, indent + "  ", v.yaw);
    s << indent << "type: ";
    Printer<uint8_t>::stream(s, indent + "  ", v.type);
    s << indent << "tracking_time: ";
    Printer<float>::stream(s, indent + "  ", v.tracking_time);
    s << indent << "tracking_level: ";
    Printer<int8_t>::stream(s, indent + "  ", v.tracking_level);
    s << indent << "lane_assignment: ";
    Printer<int8_t>::stream(s, indent + "  ", v.lane_assignment);
    s << indent << "position: ";
    s << std::endl;
    Printer< ::geometry_msgs::Point32_<ContainerAllocator> >::stream(s, indent + "  ", v.position);
    s << indent << "velocity: ";
    s << std::endl;
    Printer< ::geometry_msgs::Vector3_<ContainerAllocator> >::stream(s, indent + "  ", v.velocity);
    s << indent << "acceleration: ";
    s << std::endl;
    Printer< ::geometry_msgs::Vector3_<ContainerAllocator> >::stream(s, indent + "  ", v.acceleration);
    s << indent << "dimensions: ";
    s << std::endl;
    Printer< ::geometry_msgs::Vector3_<ContainerAllocator> >::stream(s, indent + "  ", v.dimensions);
    s << indent << "pixel_central_point: ";
    s << std::endl;
    Printer< ::perception_msgs::Point2D_<ContainerAllocator> >::stream(s, indent + "  ", v.pixel_central_point);
    s << indent << "pixel_box_size: ";
    s << std::endl;
    Printer< ::perception_msgs::Point2D_<ContainerAllocator> >::stream(s, indent + "  ", v.pixel_box_size);
  }
};

} // namespace message_operations
} // namespace ros

#endif // PERCEPTION_MSGS_MESSAGE_CAMERAOBJECT_H
